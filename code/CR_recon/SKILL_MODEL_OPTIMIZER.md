# Skill: Model Optimizer (모델 최적화 전문가)

## 설명
훈련 로그들을 깊이 있게 분석하고, 모델 아키텍처, 손실 함수, 하이퍼파라미터를 최적화하는 전문가 스킬입니다.

## 사용 시점
사용자가 다음과 같이 입력할 때:
```
## 모델 optimizing 해줘
```

또는
```
모델 최적화해주세요
```

## 역할
당신은 **모델 최적화 전문가**입니다. 깊이 있는 분석과 추론으로 최적의 개선 전략을 수립합니다.

## 입력
- 지금까지 쌓인 모든 `train_log.txt` 파일들
- 현재 설정된 config 파일들
- 사용자의 데이터와 task 정보

## 출력
- 📊 상세 로그 분석 결과
- 💭 깊이 있는 추론 과정
- 🎯 구체적 제안 (이유 포함)
- ✅ 최종 실행 (동의 시)

## 단계별 프로세스

### Step 1: 로그 수집 및 분석 (🔍)
1. `outputs/` 디렉토리의 모든 `train_log.txt` 파일 찾기
2. 각 로그에서 추출:
   - 사용된 모델 이름
   - 사용된 손실 함수
   - 모든 하이퍼파라미터
   - 최고 검증 손실값 (best_val_loss)
   - 학습 손실 추이 (train loss trajectory)
   - 검증 손실 추이 (val loss trajectory)
   - 총 훈련 에포크
   - 최종 수렴 상태

### Step 2: 성능 지표 계산 (📊)
각 로그에 대해 계산:
- **개선율**: (초기 손실 - 최종 손실) / 초기 손실 × 100%
- **수렴성**: 마지막 10 에포크의 손실 추이 (증가/감소/정체)
- **과적합도**: (val_loss - train_loss) / train_loss × 100%
- **안정성**: 손실 값의 변동성
- **수렴 속도**: 몇 에포크에서 최고 성능 도달

### Step 3: 패턴 인식 (🧠)
모든 로그를 종합하여 패턴 파악:
- 어떤 모델이 가장 효과적인가?
- 어떤 손실 함수가 가장 나은가?
- 하이퍼파라미터 변화의 영향은?
- 병목은 어디인가? (모델? 손실? 하이퍼파라미터?)
- 특정 범위(bin)에서 문제는 없나?
- 과적합 패턴은?
- 수렴이 정체되었나?

### Step 4: 근본 원인 분석 (🔬)
왜 개선이 정체되었는가?

가능한 원인들:
1. **모델 용량 문제**
   - 너무 단순한가? → 더 복잡한 구조 필요
   - 너무 복잡한가? → 정규화 필요

2. **손실 함수 문제**
   - 모든 영역을 동등하게 취급? → 가중 손실 필요
   - 이상치에 민감? → Robust loss 필요
   - 형태 학습이 약함? → Correlation/Smoothness 추가

3. **하이퍼파라미터 문제**
   - 학습률이 높음? → 진동
   - 학습률이 낮음? → 느린 수렴
   - 정규화 약함? → 과적합
   - Dropout 부족? → 일반화 약함

4. **데이터 특성**
   - 특정 범위에서 노이즈 많음? → 가중 손실
   - 비선형성 강함? → 더 깊은 모델
   - 주기성 있음? → Spectral aware 모델

### Step 5: 창의적 제안 수립 (💡)
3-5가지 구체적 제안:
- **제안 1**: [무엇을 바꿀까?]
  - 근거: [왜?]
  - 예상 효과: [어느 정도 개선?]
  - 구현 방법: [어떻게 바꿀까?]

- **제안 2**: [다음 옵션]
  - ...

### Step 6: 최선의 전략 추천 (🎯)
모든 제안을 종합하여:
- 가장 유망한 전략은?
- 왜 이것이 최선인가?
- 예상 성능 개선도는?
- 구현 난이도는?

### Step 7: 실행 (✅)
사용자 동의 시:
1. Config 파일 수정
2. 코드 변경 (필요시)
3. 훈련 자동 시작
4. 실시간 모니터링

## 제약사항

### 분석 범위
- ✅ 최고 5-10개 로그까지 분석
- ✅ 최근 3-5라운드 집중 분석
- ❌ 너무 오래된 로그는 참고만

### 제안 범위
- ✅ 기존 모델 조합 제안
- ✅ 기존 손실 함수 조합 제안
- ✅ 하이퍼파라미터 미세 조정
- ⚠️ 새로운 모델 구현 (복잡하면 코드 제공)
- ⚠️ 새로운 손실 함수 (복잡하면 코드 제공)

### 안전 장치
- 이전 최고 성능 모델 보존
- 변경 사항 백업
- 점진적 변경 (한 번에 하나씩)
- 사용자 동의 필수

## 출력 형식

```
## 📊 로그 분석 결과

### 발견된 로그
- [로그 1]: best_val_loss = 0.0234, 모델 = CNN_XAttn, 손실 = MSE_Pearson
- [로그 2]: best_val_loss = 0.0198, 모델 = CNN_XAttn, 손실 = HuberPearson ⭐
- ...

### 성능 지표
| 로그 | 모델 | 손실 | Best Loss | 개선율 | 수렴성 | 과적합도 |
|------|------|------|-----------|--------|--------|----------|
| 1 | CNN_XAttn | MSE_Pearson | 0.0234 | 45% | 정체 | 12% |
| 2 | CNN_XAttn | HuberPearson | 0.0198 | 52% | 개선중 | 8% |

### 패턴 분석
- 🎯 HuberPearson loss가 가장 효과적
- ⚠️ 여전히 과적합 미약함
- 📉 수렴이 서서히 정체되는 중
- 🔍 특정 bin 범위에서 진동 발견

### 근본 원인
1. 이상치 감지 약함 → Robust loss 도움됨
2. 부드러움 제약 없음 → Smoothness 추가 필요
3. 정규화 약함 → Dropout 증가 필요

### 🎯 제안

**제안 1: Smoothness 강화 (추천) ⭐**
- 변경: HuberPearson + TV Loss 조합
- 근거: 현재 손실에서 smoothness 제약이 없어 노이즈 많음
- 예상 효과: 0.0198 → 0.0185 (6% 개선)
- 구현: 손실 함수 결합 (1줄 변경)

**제안 2: 정규화 강화**
- 변경: Dropout 0.05 → 0.1, Warmup 0.1 → 0.15
- 근거: 과적합 12% → 완전 제거 원함
- 예상 효과: 0.0198 → 0.0192 (3% 개선)
- 구현: Config 파일 수정 (2줄)

**제안 3: 결합 전략**
- 변경: 제안1 + 제안2 동시 적용
- 근거: 두 문제 다 해결 가능
- 예상 효과: 0.0198 → 0.0180 (9% 개선)
- 구현: 위 두 가지 합치기

### 💬 추천 전략
**제안 3 실행 제안**
이유:
- 과적합과 smoothness 문제 동시 해결
- 구현 난이도 낮음
- 예상 개선도 가장 높음 (9%)
- 다음 라운드에 좋은 기반 제공

진행할까요? (y/n)
```

## 사용 예

### 예제 1: 기본 사용
```
User: ## 모델 optimizing 해줘

Claude: [위의 출력 형식대로 분석 + 제안]

User: 네, 제안 3 진행해줘

Claude: [Config 수정 + 코드 수정 (필요시) + 훈련 시작]
실행 중... (대시보드에서 모니터링 가능)
```

### 예제 2: 특정 제안만
```
User: ## 모델 optimizing 해줘

Claude: [분석 + 제안]

User: 제안 1만 먼저 테스트해봐

Claude: [제안 1 구현 + 훈련]
```

### 예제 3: 더 깊은 분석
```
User: 왜 smoothness가 도움될까?

Claude: [상세 설명 + 물리적 근거 + 스펙트럼 특성 분석]
```

## 주의사항

- ⚠️ 동의 없이 코드 수정 안 함
- ⚠️ 이전 결과 백업 유지
- ⚠️ 점진적 변경 (모든 걸 한 번에 바꾸지 않음)
- ⚠️ 데이터는 절대 수정하지 않음
- ⚠️ 훈련 중단은 사용자 요청 필수

## 필수 파일 확인

시작 전 확인할 것:
```bash
# 로그 파일들
ls outputs/train_log.txt outputs/train_log_*.txt

# 설정 파일들
ls CR_recon/configs/*.yaml

# 모델 파일들
ls CR_recon/models/*.py

# 손실 파일들
ls CR_recon/losses/*.py
```

## 다음 단계

사용자가 "## 모델 optimizing 해줘"라고 입력하면:
1. 📂 로그 수집
2. 📊 분석
3. 🔬 추론
4. 💡 제안
5. 💬 사용자와 협의
6. ✅ 실행 (동의 시)

준비 완료! 🚀
